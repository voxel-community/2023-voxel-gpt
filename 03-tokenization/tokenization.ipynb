{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Installa i pacchetti e i file necessari"
      ],
      "metadata": {
        "id": "j57UkeVUoY2b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-nlp==0.4.1\n",
        "!wget https://www.dropbox.com/s/kuxjrdz9kwxdovg/gpt_v15000_l3_h4_e100.h5\n",
        "!wget https://www.dropbox.com/s/yze44qacqgqmd1u/vocab_15000.txt"
      ],
      "metadata": {
        "id": "UkwWuv7kobTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import  os\n",
        "import  keras_nlp\n",
        "import  string\n",
        "import  numpy         as      np\n",
        "import  tensorflow    as      tf\n",
        "from    tensorflow    import  keras"
      ],
      "metadata": {
        "id": "kZTW9ITLodg1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Crea il tokenizer"
      ],
      "metadata": {
        "id": "R266u9Z3oeBm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def set_tokenizer():\n",
        "    fname       = \"vocab_15000.txt\"\n",
        "    with open( fname, 'r' ) as f:\n",
        "        vocab       = f.read()\n",
        "    vocab       = vocab.split()\n",
        "    tokenizer   = keras_nlp.tokenizers.WordPieceTokenizer(\n",
        "            vocabulary      = vocab,\n",
        "            sequence_length = 128,\n",
        "            lowercase       = True\n",
        "    )\n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "DZs19uY5of4K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testo -> lista di token\n",
        "def to_tokens( text, tokenizer ):\n",
        "    tokens      = tokenizer( text.lower() )\n",
        "    tokens      = tokens.numpy()\n",
        "    return np.trim_zeros( tokens )\n",
        "\n",
        "# lista di token -> testo    \n",
        "def from_tokens( tokens, tokenizer ):\n",
        "    text        = tokenizer.detokenize( tokens )\n",
        "    return text.numpy()    "
      ],
      "metadata": {
        "id": "RyUytAnDohSx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Testa il tokenizer"
      ],
      "metadata": {
        "id": "H0bCymsBojvN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = set_tokenizer()"
      ],
      "metadata": {
        "id": "54_2coFColwC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Why you don't you say something about it? It's wonderful!\"\n",
        "t = to_tokens( s, tokenizer )\n",
        "print( t )"
      ],
      "metadata": {
        "id": "9_84UO6LonVq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from_tokens( t, tokenizer ).decode( \"utf-8\" )"
      ],
      "metadata": {
        "id": "JhSmcXHRoo2S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from_tokens( np.arange( 300, 320 ), tokenizer ).decode( \"utf-8\" )"
      ],
      "metadata": {
        "id": "_k-MS1OyoqfK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Crea il modello di linguaggio"
      ],
      "metadata": {
        "id": "NrwD_IJ-or9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "    n_layers    = 3\n",
        "    vocab_size  = 15000\n",
        "    inputs      = keras.layers.Input( shape=(None,), dtype=tf.int32 )\n",
        "\n",
        "    embedding   = keras_nlp.layers.TokenAndPositionEmbedding(\n",
        "            vocabulary_size = vocab_size,\n",
        "            sequence_length = 128,\n",
        "            embedding_dim   = 256,\n",
        "            mask_zero       = True\n",
        "    )\n",
        "    x = embedding( inputs )\n",
        "\n",
        "    for i in range( n_layers ):\n",
        "        name    = \"decoder_{:02d}\".format( i )\n",
        "        decoder = keras_nlp.layers.TransformerDecoder(\n",
        "            num_heads           = 4,\n",
        "            intermediate_dim    = 256\n",
        "        )\n",
        "        x = decoder( x )\n",
        "\n",
        "    outputs     = keras.layers.Dense( vocab_size )( x )\n",
        "    model       = keras.Model( inputs=inputs, outputs=outputs )\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "FIYJFqY5ot4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Inizialliza il modello"
      ],
      "metadata": {
        "id": "DpysmeyBovyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init():\n",
        "    model     = create_model()\n",
        "    weights   = \"gpt_v15000_l3_h4_e100.h5\"\n",
        "    model.load_weights( weights )\n",
        "    return model"
      ],
      "metadata": {
        "id": "hiwFEvmkoyML"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = init()"
      ],
      "metadata": {
        "id": "rfRGxDTXo1Hn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Usa il modello per fare completion"
      ],
      "metadata": {
        "id": "JQjuNCC3o2r9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_prompt( tokenizer, prompt=None ):\n",
        "    p = ''\n",
        "    for c in prompt:\n",
        "        if c in string.punctuation:\n",
        "            p = p + ' ' + c\n",
        "        else:\n",
        "            p = p + c\n",
        "    prompt = p\n",
        "    \n",
        "    if prompt is None:\n",
        "        prompt_list     = [ tokenizer.token_to_id( \"[BOS]\" ) ]\n",
        "    else:\n",
        "        prompt_list     = [ tokenizer.token_to_id( w ) for w in prompt.lower().split() ]\n",
        "    prompt_tokens   = tf.convert_to_tensor( prompt_list )\n",
        "    return prompt_tokens"
      ],
      "metadata": {
        "id": "zktpChN8o5Gz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def next_token( model, tokenizer, prompt=None ):\n",
        "    prompt_tokens   = get_prompt( tokenizer, prompt )\n",
        "    prompt_tokens   = prompt_tokens[ tf.newaxis, : ]\n",
        "    prediction      = model( prompt_tokens )\n",
        "    max_prob        = tf.argmax( prediction, axis=-1 ).numpy()\n",
        "    token \t\t\t= from_tokens( max_prob, tokenizer )\n",
        "    token \t\t\t= token[ 0 ].decode( \"utf-8\" )\n",
        "    token \t\t\t= token.split( ' ' )[ -1 ]\n",
        "    return token"
      ],
      "metadata": {
        "id": "DJzUDdsbo6rJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def basic_completion( model, tokenizer, prompt=None, max_length=100 ):\n",
        "    p = prompt\n",
        "    while len( p ) < max_length:\n",
        "        t = next_token( model, tokenizer, prompt=p )\n",
        "        p = p + ' ' + t\n",
        "    return p"
      ],
      "metadata": {
        "id": "mEK3Ufzxo-OS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def top_p_completion( model, tokenizer, prompt=None, max_length=100 ):\n",
        "    prompt_tokens   = get_prompt( tokenizer, prompt )\n",
        "\n",
        "    def predict_fn( inputs ):\n",
        "        cur_len     = inputs.shape[ 1 ]\n",
        "        output      = model( inputs )\n",
        "        return output[ :, cur_len - 1, : ]\n",
        "\n",
        "    output_tokens = keras_nlp.utils.top_p_search(\n",
        "        predict_fn,\n",
        "        prompt_tokens,\n",
        "        max_length      = max_length,\n",
        "        p               = 0.5,\n",
        "        from_logits     = True\n",
        "    )\n",
        "    text            = tokenizer.detokenize( output_tokens )\n",
        "    text            = text.numpy()\n",
        "    return text"
      ],
      "metadata": {
        "id": "vVyAQr-ko_pS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Testa la completion"
      ],
      "metadata": {
        "id": "DDShZiLopBUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"There is something in here that we\"\n",
        "next_token( model, tokenizer, prompt=prompt )"
      ],
      "metadata": {
        "id": "iEROShE-pDSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"There is something in here that we\"\n",
        "basic_completion( model, tokenizer, prompt=prompt )"
      ],
      "metadata": {
        "id": "CHT_73gHpDoV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = \"There is something in here that we\"\n",
        "top_p_completion( model, tokenizer, prompt=prompt ).decode( \"utf-8\" )"
      ],
      "metadata": {
        "id": "DGeWYx4lpF4m"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}